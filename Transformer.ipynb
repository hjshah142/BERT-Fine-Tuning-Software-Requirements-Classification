{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efWCrXB1scdb"
      },
      "source": [
        "## Install tranfformer library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzAJbNdaneyz",
        "outputId": "13abda41-9417-41fe-fbe2-3af98e7afb9f"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 50.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 50.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SokIfQU8nnfQ",
        "outputId": "076cdcb5-91bb-432f-d840-64cd6ff7ad89"
      },
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/cc/a27e73cf8b23f2ce4bdd2b7089a42a7819ce6dd7366dceba406ddc5daa9c/tensorflow_gpu-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3MB 41kB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->tensorflow-gpu) (56.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.28.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.10.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n",
            "Installing collected packages: tensorflow-gpu\n",
            "Successfully installed tensorflow-gpu-2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-cIciHHnvRU"
      },
      "source": [
        "# !pip install tensorflow\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3jPgB1foNt2",
        "outputId": "d7d1e1fd-6272-4ed0-c023-f389d54cd34e"
      },
      "source": [
        " ! nvidia-smi"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu May  6 19:52:01 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HClg4-46ABn"
      },
      "source": [
        "BERT-base model that has 110 million parameters\n",
        "## Import BERT Pre-trained Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-PVX8ZPq9ob"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY6jvglnXSk4"
      },
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
        "\n",
        "#model = BertModel.from_pretrained(\"bert-base-cased\",)\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SMzNNDo5_S_",
        "outputId": "17b56fd8-3514-4b99-f35c-f8f03a439ff0"
      },
      "source": [
        "# sample data\n",
        "text = [\"The system shall refresh the display every 60 seconds.\", \n",
        "        \"The application shall match the color of the schema set forth by Department of Homeland Security.\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True)\n",
        "\n",
        "# output\n",
        "print(sent_id)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 1996, 2291, 4618, 25416, 21898, 1996, 4653, 2296, 3438, 3823, 1012, 102, 0, 0, 0, 0, 0, 0, 0], [101, 1996, 4646, 4618, 2674, 1996, 3609, 1997, 1996, 8040, 28433, 2275, 5743, 2011, 2533, 1997, 10759, 3036, 1012, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyfK4UuTaKEp"
      },
      "source": [
        "* Input ids:  dictionary of two items(sentences). Integer sequences of the input sentences.\n",
        "*  Special tokens: integers 101 and 102 \n",
        "*  Padding token : 0\n",
        "*  Attention_mask: list of 1’s and 0’s. \n",
        "* Informs the model to pay attention to the tokens corresponding to the mask value of 1 and ignore the rest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umfnd_zjeivB"
      },
      "source": [
        "# Import datasets for fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln9wDKuNeohI"
      },
      "source": [
        "script_dir = \"/content/drive/MyDrive/Colab Notebooks\""
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zaIpS6b5fgtb",
        "outputId": "52e6e7ed-d54e-414e-f3f6-a0c98430be2d"
      },
      "source": [
        "import os\n",
        "train_data_path =os.path.join(script_dir, \"RequirementsData/requirements_tags.xlsx\")\n",
        "train_data_path"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/RequirementsData/requirements_tags.xlsx'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5JleTwZg5Ep"
      },
      "source": [
        "df_train = pd.read_excel(train_data_path)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "pHcVeBzFhKTw",
        "outputId": "77592272-7c8d-47ee-c38f-78d9d5cbd209"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Requirements</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Req_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The system shall refresh the display every 60 ...</td>\n",
              "      <td>PE:</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The application shall match the color of the s...</td>\n",
              "      <td>LF:</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>If projected  the data must be readable.  On ...</td>\n",
              "      <td>US:</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The product shall be available during normal ...</td>\n",
              "      <td>A:</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>If projected  the data must be understandable...</td>\n",
              "      <td>US:</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Requirements  Tag  Req_type\n",
              "0  The system shall refresh the display every 60 ...  PE:         0\n",
              "1  The application shall match the color of the s...  LF:         0\n",
              "2   If projected  the data must be readable.  On ...  US:         0\n",
              "3   The product shall be available during normal ...   A:         0\n",
              "4   If projected  the data must be understandable...  US:         0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvbdvILSsmbk"
      },
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "train_reqs, val_reqs, train_class, val_class = train_test_split(df_train['Requirements'], df_train['Req_type'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                stratify=df_train['Req_type'])\n",
        "\n"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OQKb32Ty1J-",
        "outputId": "430d231e-a425-4476-e09b-111016f2c06e"
      },
      "source": [
        "print(train_reqs.shape)\n",
        "train_reqs.head()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(444,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "143    The product must be designed using Design Patt...\n",
              "410    The product shall be updated on a regular basi...\n",
              "449    The Disputes application shall interface with ...\n",
              "51     The product shall be easy to learn by Adjuster...\n",
              "531    The system shall display data from the Sync Ma...\n",
              "Name: Requirements, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "iWSZkFsN2gLb",
        "outputId": "600b7233-b19d-4eeb-e48e-1fed1c9414a2"
      },
      "source": [
        "\n",
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_reqs]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 12)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8ed3d79150>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fm0yqEX21yD"
      },
      "source": [
        "# Most of the requirments word lenght are between 12 to 18\n",
        "# TODO use this to decide the max length"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOUeS3dc4zG7"
      },
      "source": [
        "No need to give labels while fine tuning using pretrained  moldel to specific task based data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMBsMiKrzKn2"
      },
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_reqs.tolist(),\n",
        "    truncation=True,\n",
        "    max_length = 25,\n",
        "    padding =True\n",
        "\n",
        ")"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCSKCHBi-2-6",
        "outputId": "d66af8d8-e308-4b2c-c7a6-bdd6c6b3d582"
      },
      "source": [
        "print(tokens_train['input_ids'][0])"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[101, 1996, 4031, 2442, 2022, 2881, 2478, 2640, 7060, 1998, 16861, 2190, 6078, 1012, 3938, 1003, 1997, 6032, 4007, 9797, 2024, 2583, 2000, 17409, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRZcpMxU0b0d"
      },
      "source": [
        "# tokenize and encode sequences in the test set"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj8gclnSysCO"
      },
      "source": [
        " #return_dict=False return_dict=False return_dict=False return_dict=False# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_reqs.tolist(),\n",
        "    truncation=True,\n",
        "    max_length = 25,\n",
        "    padding =True\n",
        "    \n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuH_bJfJBM1T"
      },
      "source": [
        ""
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtAT3Dpb-bEP"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLgjO8gH-uPk"
      },
      "source": [
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_class.tolist())\n",
        "\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_class.tolist())\n",
        "\n",
        "\n"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ojCOHtKZQj_l"
      },
      "source": [
        "\n",
        "# creatr dataloader"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_ujV9WfEDLj"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WBI_V6T-dLZ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzN77-cp9gys"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5p7Hn9bH8MVn"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRLXqY1yyEfz"
      },
      "source": [
        "# Train the model"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60_logSOmiCH"
      },
      "source": [
        "# Function fine tuning the bert"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOFNhPwabDAO"
      },
      "source": [
        "# Freez bert parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT9Jrt1eu6ip"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ug58Lj98yGzL"
      },
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQx1OOysFZMY"
      },
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qz5cqYoFmQc"
      },
      "source": [
        "\n",
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozWmMoetFrGv"
      },
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 1e-5) "
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Br_0FKVFyzl",
        "outputId": "ce7763e6-f229-4353-bee4-3b680d999a5d"
      },
      "source": [
        "\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight('balanced', np.unique(train_class), train_class)\n",
        "\n",
        "print(class_wts)\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10\n"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.80434783 1.32142857]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62ZtakRpu5Hj"
      },
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecy6qXJ9GvJ3"
      },
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "    with torch.no_grad():\n",
        "          \n",
        "          # model predictions\n",
        "          preds = model(sent_id, mask)\n",
        "\n",
        "          # compute the validation loss between actual and predicted values\n",
        "          loss = cross_entropy(preds,labels)\n",
        "\n",
        "          total_loss = total_loss + loss.item()\n",
        "\n",
        "          preds = preds.detach().cpu().numpy()\n",
        "\n",
        "          total_preds.append(preds)\n",
        "\n",
        "      # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "      # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCFvgoy4VNnC",
        "outputId": "8f951f73-1ff7-497d-acbe-95ca847e85a3"
      },
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.681\n",
            "Validation Loss: 0.677\n",
            "\n",
            " Epoch 2 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.678\n",
            "Validation Loss: 0.678\n",
            "\n",
            " Epoch 3 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.682\n",
            "Validation Loss: 0.678\n",
            "\n",
            " Epoch 4 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.676\n",
            "Validation Loss: 0.677\n",
            "\n",
            " Epoch 5 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.674\n",
            "Validation Loss: 0.678\n",
            "\n",
            " Epoch 6 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.683\n",
            "Validation Loss: 0.674\n",
            "\n",
            " Epoch 7 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.673\n",
            "Validation Loss: 0.673\n",
            "\n",
            " Epoch 8 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.681\n",
            "Validation Loss: 0.673\n",
            "\n",
            " Epoch 9 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.674\n",
            "Validation Loss: 0.674\n",
            "\n",
            " Epoch 10 / 10\n",
            "\n",
            "Evaluating...\n",
            "\n",
            "Training Loss: 0.674\n",
            "Validation Loss: 0.673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gY1cUQhTW1Eb",
        "outputId": "4a6af2f5-ea1a-44b6-919b-9aad8692db9f"
      },
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-hto4ViwiEiM",
        "outputId": "8925956b-560e-452e-fd8f-404a0e290b3f"
      },
      "source": [
        "import os\n",
        "test_data_path =os.path.join(script_dir, \"RequirementsData/requirements_tags_test.xlsx\")\n",
        "test_data_path"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Colab Notebooks/RequirementsData/requirements_tags_test.xlsx'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3D71aNOi5Pq"
      },
      "source": [
        "test_df = pd.read_excel(test_data_path)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "O9EiZ-pgjba4",
        "outputId": "a994fee8-4f7f-4480-dd59-1497c9e2ed6a"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Requirements</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Req_type_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The system shall display Events or Activities.</td>\n",
              "      <td>F:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The display shall have two regions:  left 2/3...</td>\n",
              "      <td>F:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The data displayed in both the nodes within th...</td>\n",
              "      <td>F:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The table side of the display shall be split i...</td>\n",
              "      <td>F:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The top 1/4 of the table will hold events that...</td>\n",
              "      <td>F:</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        Requirements Tag  Req_type_test\n",
              "0     The system shall display Events or Activities.  F:              1\n",
              "1   The display shall have two regions:  left 2/3...  F:              1\n",
              "2  The data displayed in both the nodes within th...  F:              1\n",
              "3  The table side of the display shall be split i...  F:              1\n",
              "4  The top 1/4 of the table will hold events that...  F:              1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYSTMX3KhnIG"
      },
      "source": [
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_df['Requirements'].tolist(),\n",
        "    truncation=True,\n",
        "    max_length = 25,\n",
        "    padding =True\n",
        "\n",
        ")"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuNlm926kf9x"
      },
      "source": [
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_df['Req_type_test'].tolist())"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAAXK1Rqgfg3"
      },
      "source": [
        "\n",
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNJ4tipIgoH7",
        "outputId": "1674c8f6-dc1c-410b-ee91-8bc5ba5a563e"
      },
      "source": [
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.92      0.58        25\n",
            "           1       0.88      0.31      0.46        45\n",
            "\n",
            "    accuracy                           0.53        70\n",
            "   macro avg       0.65      0.62      0.52        70\n",
            "weighted avg       0.71      0.53      0.50        70\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "Q1PHj088g-hw",
        "outputId": "41bdbdca-713a-4a07-ecaa-23a708b0bfed"
      },
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>23</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0   0   1\n",
              "row_0        \n",
              "0      23   2\n",
              "1      31  14"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ctTlSBVhCaR"
      },
      "source": [
        "# for test set\n",
        "test_labels = test_df['Req_type_test']\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ],
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmypdp8zhOBZ"
      },
      "source": [
        "# split train dataset into train, validation and test sets\n",
        "train_reqs, val_reqs, train_class, val_class = train_test_split(df_train['Requirements'], df_train['Req_type'], \n",
        "                                                                    random_state=2018, \n",
        "                                                                    test_size=0.2, \n",
        "                                                                stratify=df_train['Req_type'])\n"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS9g1lt3lwsF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}